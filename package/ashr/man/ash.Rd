% Generated by roxygen2 (4.1.0): do not edit by hand
% Please edit documentation in R/ash.R
\name{ash}
\alias{ash}
\title{Main Adaptive Shrinkage function}
\usage{
ash(betahat, sebetahat, method = c("shrink", "fdr"),
  mixcompdist = c("uniform", "halfuniform", "normal"), lambda1 = 1,
  lambda2 = 0, nullcheck = TRUE, df = NULL, randomstart = FALSE,
  nullweight = 10, nonzeromode = FALSE, pointmass = FALSE,
  onlylogLR = FALSE, prior = c("uniform", "nullbiased"), mixsd = NULL,
  VB = FALSE, gridmult = sqrt(2), minimaloutput = FALSE,
  multiseqoutput = FALSE, g = NULL, K = 1, maxiter = 5000,
  retol = 1e-05, trace = FALSE, cxx = FALSE, model = c("EE", "ES"))
}
\arguments{
\item{betahat}{a p vector of estimates}

\item{sebetahat}{a p vector of corresponding standard errors}

\item{method}{specifies how ash is to be run. Can be "shrinkage" (if main aim is shrinkage) or "fdr" (if main aim is to assess fdr or fsr)
This is simply a convenient way to specify certain combinations of parameters: "shrinkage" sets pointmass=FALSE and prior="uniform";
"fdr" sets pointmass=TRUE and prior="nullbiased".}

\item{mixcompdist}{distribution of components in mixture ( "uniform","halfuniform" or "normal"), the default value would be "uniform"}

\item{lambda1}{multiplicative "inflation factor" for standard errors (like Genomic Control)}

\item{lambda2}{additive "inflation factor" for standard errors (like Genomic Control)}

\item{nullcheck}{whether to check that any fitted model exceeds the "null" likelihood
in which all weight is on the first component}

\item{df}{appropriate degrees of freedom for (t) distribution of betahat/sebetahat, default is NULL(Gaussian)}

\item{randomstart}{logical, indicating whether to initialize EM randomly. If FALSE, then initializes to prior mean (for EM algorithm) or prior (for VBEM)}

\item{nullweight}{scalar, the weight put on the prior under "nullbiased" specification, see \code{prior}}

\item{nonzeromode}{logical, indicating whether to use a non-zero unimodal mixture(default is "FALSE")}

\item{pointmass}{logical, indicating whether to use a point mass at zero as one of components for a mixture distribution}

\item{onlylogLR}{logical, indicating whether to use this function to get logLR. Skip posterior prob, posterior mean, lfdr...}

\item{prior}{string, or numeric vector indicating Dirichlet prior on mixture proportions (defaults to "uniform", or (1,1...,1); also can be "nullbiased" (nullweight,1,...,1) to put more weight on first component)}

\item{mixsd}{vector of sds for underlying mixture components}

\item{VB}{whether to use Variational Bayes to estimate mixture proportions (instead of EM to find MAP estimate), see \code{\link{mixVBEM}} and \code{\link{mixEM}}}

\item{gridmult}{the multiplier by which the default grid values for mixsd differ by one another. (Smaller values produce finer grids)}

\item{minimaloutput}{if TRUE, just outputs the fitted g and the lfsr (useful for very big data sets where memory is an issue)}

\item{multiseqoutput}{if TRUE, just outputs the fitted g, logLR, PosteriorMean, PosteriorSD, function call and df}

\item{g}{the prior distribution for beta (usually estimated from the data; this is used primarily in simulated data to do computations with the "true" g)}

\item{K}{An integer denoting the order of the SQUAREM scheme. Default is 1,i.e. first-order schemes, which is adequate for most problems. K=2,3 may provide greater speed in some problems, although they are less reliable than the first-order schemes.}

\item{maxiter}{maximum number of iterations of the EM algorithm.}

\item{retol}{the relelative precision for the mode of mixture when nonzeromode=TRUE, the default value is 1e-5.}

\item{trace}{a logical variable denoting whether some of the intermediate results of iterations should be displayed to the user. Default is FALSE.}

\item{cxx}{flag to indicate whether to use the c++ (Rcpp) version. After application of Squared extrapolation methods for accelerating fixed-point iterations (R Package "SQUAREM"), the c++ version is no longer faster than non-c++ version, thus we do not recommend using this one, and might be removed at any point.}

\item{model}{c("EE","ES") specifies whether to assume exchangeable effects (EE) or exchangeable standardized effects (ES).}

\item{control}{A list of control parameters specifing any changes to default values of algorithm control parameters. Full names of control list elements must be specified, otherwise, user-specifications are ignored. See Details.}
}
\value{
ash returns an object of \code{\link[base]{class}} "ash", a list with the following elements(or a  simplified list, if \eqn{onlylogLR=TRUE}, \eqn{minimaloutput=TRUE}   or \eqn{multiseqoutput=TRUE}) \cr
\item{fitted.g}{fitted mixture, either a normalmix or unimix}
\item{logLR}{log P(D|mle(pi)) - log P(D|null)}
\item{loglik}{log P(D|mle(pi))}
\item{PosteriorMean}{A vector consisting the posterior mean of beta from the mixture}
\item{PosteriorSD}{A vector consisting the corresponding posterior standard deviation}
\item{PositiveProb}{A vector of posterior probability that beta is positive}
\item{NegativeProb}{A vector of posterior probability that beta is negative}
\item{ZeroProb}{A vector of posterior probability that beta is zero}
\item{lfsr}{The local false sign rate}
\item{lfsra}{The local false sign rate(adjusted)}
\item{lfdr}{A vector of estimated local false discovery rate}
\item{qvalue}{A vector of q values}
\item{fit}{The fitted mixture object by \code{\link{mixEM}} or \code{\link{mixVBEM}} }
\item{lambda1}{multiplicative "inflation factor"}
\item{lambda2}{additive "inflation factor"}
\item{call}{a call in which all of the specified arguments are specified by their full names}
\item{data}{a list consisting the input betahat and sebetahat}
\item{excludeindex}{the vector of index of observations with 0 standard error; if none, then returns NULL}
\item{df}{the specified degrees of freedom for (t) distribution of betahat/sebetahat}
\item{model}{either "EE" or "ES", denoting whether exchangeable effects (EE) or exchangeable standardized effects (ES) has been used}
}
\description{
Takes vectors of estimates (betahat) and their standard errors (sebetahat), and applies
shrinkage to them, using Empirical Bayes methods, to compute shrunk estimates for beta.
}
\details{
See readme for more details
}
\examples{
beta = c(rep(0,100),rnorm(100))
sebetahat = abs(rnorm(200,0,1))
betahat = rnorm(200,beta,sebetahat)
beta.ash = ash(betahat, sebetahat)
summary(beta.ash)
plot(betahat,beta.ash$PosteriorMean,xlim=c(-4,4),ylim=c(-4,4))

CIMatrix=ashci(beta.ash,level=0.95)
print(CIMatrix)

betahat=betahat+5
beta.ash = ash(betahat, sebetahat)
summary(beta.ash)
plot(betahat,beta.ash$PosteriorMean)

#Testing the non-zero mode feature
betahat=betahat+5
betan.ash=ash(betahat, sebetahat,nonzeromode=TRUE)
plot(betahat, betan.ash$PosteriorMean)
}
\seealso{
\code{\link{ashci}} for computation of credible intervals after getting the ash object return by \code{ash()}

\code{\link{ashm}} for Multi-model Adaptive Shrinkage function
}

